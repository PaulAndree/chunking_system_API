# chunking_system_API


Esta API desarrollada con FastApi busca exponer un endpoint "/process_doc" el cual es capaz de procesar un archivo (pdf, docx, txt) y segmentarlo semanticamente, devolviendo una lista de chunks. Los parametros posibles a configurar para la segmentacion son los siguientes:

```python
splitter_pdf = RollingWindowSplitter(
    encoder=encoder,
    dynamic_threshold=True,
    min_split_tokens=150,
    max_split_tokens=300,
    window_size=5,
    plot_splits=False,  # set this to true to visualize chunking
    enable_statistics=False  # to print chunking stats
)
```

üîπ min_split_tokens define el tama√±o m√≠nimo de un chunk en tokens.
üîπ max_split_tokens Define el tama√±o m√°ximo del chunk antes de forzar un corte.
üîπ window_size  Controla el overlap sem√°ntico entre chunks.
üîπ dynamic_threshold  Esto ajusta din√°micamente los cortes seg√∫n la coherencia sem√°ntica detectada por el encoder.


El c√≥digo para esta ingesta se basa fundamentalmente en [MinerU](https://github.com/opendatalab/MinerU) y [semantic-router](https://pypi.org/project/semantic-router/).  
MinerU es una herramienta de c√≥digo abierto desarrollada por OpenDataLab, dise√±ada para facilitar el an√°lisis y procesamiento de documentos complejos, como art√≠culos acad√©micos, informes t√©cnicos y libros de texto y llevarlos a formatos estructurados como Markdown y JSON. Sus principales caracteristicas y uso son:

‚úÖ An√°lisis de dise√±o avanzado: Utiliza modelos como DocLayout-YOLO para detectar y estructurar elementos del documento, incluyendo encabezados, tablas, texto y f√≥rmulas.

‚úÖ Extracci√≥n precisa de contenido: Elimina autom√°ticamente elementos redundantes como encabezados, pies de p√°gina y n√∫meros de p√°gina, preservando la coherencia sem√°ntica del texto.

‚úÖ Reconocimiento de f√≥rmulas matem√°ticas: Convierte f√≥rmulas matem√°ticas en formato LaTeX, facilitando su edici√≥n y an√°lisis.

‚úÖ Reconocimiento de tablas: Detecta y extrae tablas, represent√°ndolas en formato HTML para su posterior procesamiento

Por otro lado semantic-router es usado para implementar la segmentaci√≥n sem√°ntica de manera automatizada, ya que permite directamente configurar parametros de segmentaci√≥n.

Ejemplo para llamar a la API:

```python
import requests
url = "http://localhost:8071/process_doc"

response = requests.post(
    url,
    data={"type_name": "note", "content": content, "language": "es"}
)
chunks = response.json()
chunks
```

```python
 # for pdf

import requests
url =  "http://localhost:8071/process_doc"


response = requests.post(
    url,
    files={"file": open( "/home/peyzaguirre/notebooks/dev_chunking_system/table.pdf", "rb")},
    data={"type_name": "pdf","output_dir":"/home/peyzaguirre/notebooks/dev_chunking_system/output", "language":"es"}
)
chunks = response.json()
```

```python
 # for doc
response = requests.post(
    "http://localhost:8071/process_doc",
    files={"file": open( "/home/peyzaguirre/notebooks/dev_chunking_system/Carta.docx", "rb")},
    data={"type_name": "doc","output_dir":"/home/peyzaguirre/notebooks/dev_chunking_system/output", "language":"es"}
)
chunks_doc = response.json()
chunks_doc[0]
```


Find the docker image at :

docker pull paulbarreda9/chunking-api:latest

