# chunking_system_API


Esta API desarrollada con FastApi expone un endpoint "/process_doc" el cual es capaz de procesar un archivo (pdf, docx, txt) y segmentarlo sem√°nticamente, devolviendo una lista de chunks. Los par√°metros posibles a configurar para la segmentaci√≥n son los siguientes:

```python
splitter_pdf = RollingWindowSplitter(
    encoder=encoder, #intfloat/multilingual-e5-large
    dynamic_threshold=True,
    min_split_tokens=150,
    max_split_tokens=300,
    window_size=5,
    plot_splits=False,  
    enable_statistics=False 
```

üîπ min_split_tokens define el tama√±o m√≠nimo de un chunk en tokens.  
üîπ max_split_tokens Define el tama√±o m√°ximo del chunk antes de forzar un corte. <br>
üîπ window_size  Controla el overlap sem√°ntico entre chunks.  
üîπ dynamic_threshold  Esto ajusta din√°micamente los cortes seg√∫n la coherencia sem√°ntica detectada por el encoder.


Docker image:
docker pull paulbarreda9/chunking-api:latest


El c√≥digo para la ingesta y procesamiento de documentos se basa fundamentalmente en [MinerU](https://github.com/opendatalab/MinerU) y [semantic-router](https://pypi.org/project/semantic-router/). MinerU es una herramienta de c√≥digo abierto desarrollada por OpenDataLab, dise√±ada para facilitar el an√°lisis y procesamiento de documentos complejos, como art√≠culos acad√©micos, informes t√©cnicos y libros de texto y llevarlos a formatos estructurados como Markdown y JSON. Utiliza modelos como DocLayout-YOLO para detectar y estructurar elementos del documento, incluyendo encabezados, tablas, texto y f√≥rmulas. Elimina autom√°ticamente elementos redundantes como encabezados, pies de p√°gina y n√∫meros de p√°gina, preservando la coherencia sem√°ntica del texto. Convierte f√≥rmulas matem√°ticas en formato LaTeX, facilitando su edici√≥n y an√°lisis. Detecta y extrae tablas, represent√°ndolas en formato HTML para su posterior procesamiento.  
Por otro lado semantic-router es usado para implementar directamente la segmentaci√≥n sem√°ntica permitiendo configurar parametros de la segmentaci√≥n.

Ejemplo para llamar a la API:

```python
 # for txt

import requests
url = "http://localhost:8071/process_doc"

response = requests.post(
    url,
    data={"type_name": "note", "content": content, "language": "es"}
)
chunks = response.json()
chunks
```

```python
 # for pdf

import requests
url =  "http://localhost:8071/process_doc"


response = requests.post(
    url,
    files={"file": open( "/home/peyzaguirre/notebooks/dev_chunking_system/table.pdf", "rb")},
    data={"type_name": "pdf","output_dir":"/home/peyzaguirre/notebooks/dev_chunking_system/output", "language":"es"}
)
chunks = response.json()
```

```python
 # for doc

response = requests.post(
    url,
    files={"file": open( "/home/peyzaguirre/notebooks/dev_chunking_system/Carta.docx", "rb")},
    data={"type_name": "doc","output_dir":"/home/peyzaguirre/notebooks/dev_chunking_system/output", "language":"es"}
)
chunks_doc = response.json()
chunks_doc[0]
```


## EVALUACI√ìN


Partiendo de que uno de los principales objetivos de un sistema de recuperaci√≥n en aplicaciones de IA es identificar y recuperar √∫nicamente los tokens relevantes para una consulta determinada, proponemos una estrategia de evaluaci√≥n que mide a nivel de token la efectividad de la estrategia de segmentaci√≥n utilizada en el retrieval. Las m√©tricas utilizadas son precisi√≥n, recuperaci√≥n e intersecci√≥n sobre uni√≥n ( [√≠ndice Jaccard](https://en.wikipedia.org/wiki/Jaccard_index) ) a partir de los tokens recuperados .

Gneraci√≥n de conjunto de datos:

Para el experimento 1, hemos utilizado un dataset peque√±o que consiste en una consulta generada manualmente sobre un documento de caracter legal, y un pasaje o p√°rrafo del documento que responde a dicha consulta. Por ejemplo:

<pre> ```
Cosulta generada por un humano : "¬øcuales son las reglas que las administraciones publicas deben ajustarse para  garantizar la identidad y contenido de las copias electr√≥nicas o en papel? "
Extracto sacado del documento =   Para garantizar la identidad y contenido de las copias electr√≥nicas o en papel, y por tanto su car√°cter de copias aut√©nticas, las Administraciones P√∫blicas deber√°n ajustarse a lo previsto en el Esquema Nacional de Interoperabilidad, el Esquema Nacional de Seguridad y sus normas t√©cnicas de desarrollo, as√≠ como a las siguientes reglas: 
a) Las copias electr√≥nicas de un documento electr√≥nico original o de una copia electr√≥nica aut√©ntica, con o sin cambio de formato, deber√°n incluir los metadatos que acrediten su condici√≥n de copia y que se visualicen al consultar el documento. 
b) Las copias electr√≥nicas de documentos en soporte papel o en otro soporte no electr√≥nico susceptible de digitalizaci√≥n, requerir√°n que el documento haya sido digitalizado y deber√°n incluir los metadatos que acrediten su condici√≥n de copia y que se visualicen al consultar el documento. 
c) Las copias en soporte papel de documentos electr√≥nicos requerir√°n que en las mismas figure la condici√≥n de copia y contendr√°n un c√≥digo generado electr√≥nicamente u otro sistema 
...

``` </pre>

## M√âTRICAS


### IOU

Para una consulta relacionada a un corpus espec√≠fico, solo un subconjunto de tokens dentro de ese corpus ser√° relevante. Idealmente, un sistema de recuperaci√≥n deber√≠a recuperar exactamente y √∫nicamente los tokens relevantes para cada consulta en todo el corpus. La metrica Intersecci√≥n sobre Uni√≥n (IoU) es una m√©trica que considera no solo si se recuperan fragmentos relevantes, sino tambi√©n cu√°ntos tokens irrelevantes, redundantes o distractores se recuperan.

$$
\text{IoU}_q(\mathbf{C}) = \frac{|t_e \cap t_r|}{|t_e| + |t_r| - |t_e \cap t_r|}
$$



Donde:
- \( t_e \): conjunto de tokens esperados o relevantes (ground truth).
- \( t_r \): conjunto de tokens recuperados por el sistema.
- \( q_i \): query
- \( C \): Chunked corpus

Interpretaci√≥n:   Si el sistema recupera exactamente los mismos tokens que los relevantes ‚Üí IoU = 1. Si no hay solapamiento ‚Üí IoU = 0

### Precision

$$
\text{Precision}_q(\mathbf{C}) = \frac{|t_e \cap t_r|}{ |t_r| }
$$

Interpretaci√≥n: mide cu√°ntos de los tokens recuperados eran realmente relevantes. (se ven cuanto ruido o falsos positivos hay en la recuperacion).


### Recall

$$
\text{Recall}_q(\mathbf{C}) = \frac{|t_e \cap t_r|}{ |t_e| }
$$

Interpretaci√≥n:  mide cu√°ntos de los tokens relevantes fueron efectivamente recuperados.



## Resultados

El experimento 1 se enfoca en evaluar los par√°metros de configuraci√≥n estandar, mientras que el experimento 2 incorpora un enfoque recursivo, donde primero divide un documento en segmentos usando los titulos como l√≠mite de corte y contin√∫a con la divisi√≥n sem√°ntica para cada segmento. Se observa que este √∫ltimo experimento mejora la recuperaci√≥n de las consultas. En las gr√°ficas se muestra adem√°s el resultado obtenido con diferentes tama√±os de chunks.

<p align="center">
  <img src="IOU.png" alt="Gr√°fico IoU" width="500">
</p>


<p align="center">
  <img src="Precission.png" alt="Gr√°fico Precission" width="500">
</p>


<p align="center">
  <img src="Recall.png" alt="Gr√°fico Recall" width="500">
</p>


